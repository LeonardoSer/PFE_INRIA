{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f53c85e4-2dd6-4630-a855-5e802c03fbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import random\n",
    "import numpy \n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path \n",
    "import sys\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abbeecf8-b308-43f4-ac5f-62518f5f6c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read all datasets for every hole size, splitted by starting year, and plot them\n",
    "YEARS = [str(year) for year in range(1990,2019)]\n",
    "collaborations_df = pd.read_csv('myDATA/00-collaboration_df_with_starting_years.csv')\n",
    "min_size = 1\n",
    "max_size = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5cf2e7c-ec09-4a99-995e-da5d6410b58d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_tot_auths_num():\n",
    "    file = 'myDATA/00-collaboration_df_with_starting_years.csv'\n",
    "    collaborations_df = pd.read_csv(file)\n",
    "    num_auths_by_y = []\n",
    "    num_new_auths_by_y = []\n",
    "    YEARS = [str(year) for year in range(1990,2019)]  \n",
    "    tot_auth = 0\n",
    "    for i in range(len(YEARS)):\n",
    "        y = YEARS[i]\n",
    "        \n",
    "        # number of new authors in the given year\n",
    "        num_new_auths_by_y.append(len(collaborations_df.loc[collaborations_df[\"start_year\"] == int(y)]))\n",
    "        \n",
    "        # total number of new authors in the given year\n",
    "        tot_auth += num_new_auths_by_y[i]                         \n",
    "        num_auths_by_y.append(tot_auth)\n",
    "    return num_auths_by_y\n",
    "\n",
    "# return a vector containig the total number of collaboration for each year\n",
    "def get_tot_collabs_num():\n",
    "    file = 'myDATA/00-collaboration_df_with_starting_years.csv'\n",
    "    collaborations_df = pd.read_csv(file)\n",
    "    num_colls_by_y = []\n",
    "    YEARS = [str(year) for year in range(1990,2019)]  \n",
    "    tot_auth = 0\n",
    "    for i in range(len(YEARS)):\n",
    "        y = YEARS[i]\n",
    "        # total number of collaborations in the given year\n",
    "        num_colls_by_y.append(collaborations_df[y].sum())\n",
    "    return num_colls_by_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19236457-c84e-4d34-87e0-c63d5da0a684",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f_by_auth(df):\n",
    "    x=[]\n",
    "    y=[]\n",
    "    j=0\n",
    "    tot_auths = get_tot_auths_num()\n",
    "    for i in df:\n",
    "        if(i!=\"ID\"):\n",
    "            y.append(df[i].mean())\n",
    "            x.append(tot_auths[j])\n",
    "            j+=1\n",
    "    return x,y\n",
    "\n",
    "def get_f_by_colls(df):\n",
    "    \n",
    "    tot_colls = get_tot_collabs_num()\n",
    "    x=[]\n",
    "    y=[]\n",
    "    for i in df:\n",
    "        if(i!=\"ID\"):\n",
    "            y.append(df[i].mean())\n",
    "            j=YEARS.index(str(i))\n",
    "            x.append(tot_colls[j])\n",
    "            \n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fc21c1f-cb1b-4cd8-9732-63d8b62764d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# computer error between each fitted curve and real data\n",
    "def err_calc_polyfit(y, y1):\n",
    "    err = 0\n",
    "    for i in range(len(y)):\n",
    "        err += pow(abs(y[i] - y1[i]), 2)\n",
    "    return err\n",
    "\n",
    "def tot_err_polyfit(x_y_fit):\n",
    "    total_error = 0\n",
    "    for y in YEARS[:-1]:\n",
    "        err = err_calc_polyfit(x_y_fit[y][\"y\"], x_y_fit[y][\"fit_y\"])\n",
    "        total_error += err\n",
    "    return str(total_error)\n",
    "\n",
    "# compute error for the general function \n",
    "def err_calc(y, y1):\n",
    "    err = 0\n",
    "    for i in range(len(y)):\n",
    "        err += pow(abs(y[i] - y1[i]), 2)\n",
    "    return err\n",
    "\n",
    "def tot_err(gamma, beta):\n",
    "    total_error = 0\n",
    "    for y in YEARS[:-1]:\n",
    "        err = err_calc(x_y_fit[y][\"y\"],best_g(x_y_fit[y][\"x\"], gamma, beta))\n",
    "        total_error += err\n",
    "    return str(total_error)\n",
    "\n",
    "def func1(t, tv, gamma, beta):\n",
    "    return (1+gamma)* pow((t/tv), beta) - gamma\n",
    "\n",
    "def best_g(xdata, gamma, beta):\n",
    "    y = []\n",
    "    for x in xdata:\n",
    "        y.append(func1(x, xdata[0], gamma, beta))\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1c0a91f-324d-47eb-8ab0-81f4381d42a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the best values for gamma and beta\n",
    "import scipy.optimize as optimize\n",
    "\n",
    "def f(params):\n",
    "    gamma, beta = params\n",
    "    tot = 0\n",
    "    for v in YEARS[:-1]:\n",
    "        t_v = x_y_fit[v][\"x\"][0]\n",
    "        for i in range(len(x_y_fit[v][\"x\"])):\n",
    "            t_i = x_y_fit[v][\"x\"][i]\n",
    "            f = x_y_fit[v][\"y\"][i]\n",
    "            tot += pow(abs(f - gamma * pow((t_i/t_v), beta)) - gamma, 2)\n",
    "    \n",
    "    return tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "776619b6-0ac7-4b3b-b1f7-494bbe3338e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================ \u001b[1mHOLE SIZE 1\u001b[0m =================================================================\n",
      "1990 -> gamma -0.6330775436662227 , beta 0.6733801527670561\n",
      "1991 -> gamma -0.033129379018743105 , beta 0.6653976252507253\n",
      "1992 -> gamma 0.399299723687501 , beta 0.6593833989687344\n",
      "1993 -> gamma 1.507709530300348 , beta 0.6162088539713094\n",
      "1994 -> gamma 0.1975867051860178 , beta 0.736318765379639\n",
      "1995 -> gamma 0.2275138936460873 , beta 0.8259570057208867\n",
      "1996 -> gamma 3.036836255535408 , beta 0.6991525218092545\n",
      "1997 -> gamma 2.051663980768967 , beta 0.7783710755129342\n",
      "1998 -> gamma 2.2191802331415316 , beta 0.8247892087744793\n",
      "1999 -> gamma 1.8501965543538816 , beta 0.8735366481824982\n",
      "2000 -> gamma 2.8713875970642593 , beta 0.8492227456750439\n",
      "2001 -> gamma 5.348069155378264 , beta 0.8159154298522959\n"
     ]
    },
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-fca94790de81>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m                     \u001b[0mpng_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"myDATA/10-splitted_by_year/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_hole_size_splitted/trajectories_avg_plt/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_holeSize_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"by_num_collaborations_poly_fittings_all\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".png\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m                     \u001b[0mcurr_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_tot_collabs_num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mYEARS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m                     \u001b[0mx_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_f_by_colls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\" -> \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-b7f6fcab4ab0>\u001b[0m in \u001b[0;36mget_tot_collabs_num\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_tot_collabs_num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'myDATA/00-collaboration_df_with_starting_years.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mcollaborations_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mnum_colls_by_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mYEARS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0myear\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1990\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2019\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m         \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'."
     ]
    }
   ],
   "source": [
    "gammas  = []\n",
    "betas = []\n",
    "\n",
    "def func(t, gamma, beta):\n",
    "    return (1 + gamma) * pow(t, beta) - gamma\n",
    "\n",
    "def plot_f_fit(xdata, ydata, curr_x):\n",
    "    popt, pcov = curve_fit(func, [x/curr_x for x in xdata], ydata, maxfev=5000)\n",
    "    gammas.append(popt[0])\n",
    "    betas.append(popt[1])\n",
    "    print(\"gamma\", popt[0], \", beta\", popt[1])\n",
    "    return func([x/curr_x for x in xdata], *popt)\n",
    "\n",
    "# Plot fitting function of average trajectories for each starting year and hole lenght stretched by new collaborations\n",
    "for size in range(min_size, max_size+1):\n",
    "    gammas  = []\n",
    "    betas = []\n",
    "    x_y_fit = {}\n",
    "    \n",
    "    print((' \\033[1m' + \"HOLE SIZE \"+str(size) + '\\033[0m ').center(150, '='))\n",
    "    path = 'myDATA/10-splitted_by_year/'+str(size)+'_hole_size_splitted'\n",
    "    if(os.path.exists(path)):\n",
    "        for y in YEARS:\n",
    "            file=path+'/'+y+'_collabs_by_starting_year.csv'\n",
    "            if(os.path.exists(file) and y!=\"2018\"):\n",
    "                df_y = pd.read_csv(file)\n",
    "                if(len(df_y)>0):\n",
    "                    png_path = \"myDATA/10-splitted_by_year/\"+str(size)+\"_hole_size_splitted/trajectories_avg_plt/\"+\"_holeSize_\"+str(size)+\"by_num_collaborations_poly_fittings_all\"+\".png\"\n",
    "\n",
    "                    curr_x = get_tot_collabs_num()[YEARS.index(y)]\n",
    "                    x_axis, y_axis = get_f_by_colls(df_y)  \n",
    "                    print(y, end=\" -> \")\n",
    "                    fit_y = plot_f_fit(x_axis, y_axis, curr_x)\n",
    "                    \n",
    "                    x_y_fit[y] = {\"x\":x_axis, \"y\":y_axis, \"fit_y\":fit_y }\n",
    "    \n",
    "    plt.figure(figsize=(20, 8), dpi=80)\n",
    "\n",
    "    for y in YEARS[:-1]:\n",
    "        plt.plot(x_y_fit[y][\"x\"], x_y_fit[y][\"y\"])\n",
    "        plt.plot(x_y_fit[y][\"x\"], x_y_fit[y][\"fit_y\"], 'r--') \n",
    "        \n",
    "    plt.xlabel(\"years stretched by # collaborations\")\n",
    "    plt.ylabel(\"avg num_Collaborations\")\n",
    "    plt.xticks(rotation='vertical')\n",
    "    plt.xticks(get_tot_collabs_num(), YEARS)\n",
    "\n",
    "    plt.savefig(png_path)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    print(\"total error for all fitted curves\", tot_err_polyfit(x_y_fit))\n",
    "    \n",
    "    initial_guess = [1, 1]\n",
    "    result = optimize.minimize(f, initial_guess)\n",
    "    fitted_params = result.x\n",
    "    \n",
    "    ## both optimized values \n",
    "    gamma = fitted_params[0]\n",
    "    beta = fitted_params[1]\n",
    "    print(gamma, beta)\n",
    "    ## fixing gamma to the mean \n",
    "    # gamma_mean = np.mean(gammas) # mean\n",
    "    # beta1 = 1.5135571015789293 # for hole size 1\n",
    "\n",
    "    ## fixing beta to the mean \n",
    "    # beta_mean = np.mean(betas) # mean \n",
    "    # gamma1 = 0.138066456038629  # for hole size 1\n",
    "\n",
    "    for y in YEARS[:-1]:\n",
    "        print((' \\033[1m' + \"starting year \"+str(y) + '\\033[0m ').center(150, '='))\n",
    "        plt.figure(figsize=(20, 5), dpi=80)\n",
    "\n",
    "        plt.plot(x_y_fit[y][\"x\"], x_y_fit[y][\"y\"], label=\"data\")\n",
    "        plt.plot(x_y_fit[y][\"x\"], x_y_fit[y][\"fit_y\"], 'r--', label=\"poly fit with err = \"+tot_err_polyfit(x_y_fit))\n",
    "        plt.plot(x_y_fit[y][\"x\"], best_g(x_y_fit[y][\"x\"], gamma, beta), label=\"both gamma and beta optimized, with err = \"+tot_err(gamma, beta))\n",
    "        #plt.plot(x_y_fit[y][\"x\"], best_g(x_y_fit[y][\"x\"], gamma_mean, beta1), label=\"gamma fixed to mean and beta optimized , with total err = \"+tot_err(gamma_mean, beta1))\n",
    "        #plt.plot(x_y_fit[y][\"x\"], best_g(x_y_fit[y][\"x\"], gamma1, beta_mean), label=\"beta fixed to mean and gamma optimized , with total err = \"+tot_err(gamma1, beta_mean))\n",
    "\n",
    "        plt.xlabel(\"years stretched by # collaborations\")\n",
    "        plt.ylabel(\"avg num_Collaborations\")\n",
    "        plt.xticks(rotation='vertical')\n",
    "        plt.xticks(get_tot_collabs_num(), YEARS)\n",
    "        plt.legend()\n",
    "        \n",
    "        fig_path = \"myDATA/10-splitted_by_year/\"+str(size)+\"_hole_size_splitted/trajectories_avg_plt/\" + str(y) + \"_by_num_collaborations_gamma_beta_poly_fitting_generalized.png\"\n",
    "        plt.savefig(fig_path)\n",
    "        plt.show()\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
